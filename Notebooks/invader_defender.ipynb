{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invader Defender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import pickle\n",
    "from scipy.optimize import linprog\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "# to remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [[-1, 0], [0, 1], [1, 0], [0, -1]] #up, right, down, left = (clockwise from up) \n",
    "action_count = len(actions) \n",
    "gridSize = 6 \n",
    "state_count = gridSize*gridSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Invader_Defender():\n",
    "    def __init__(self, gridSize):\n",
    "        self.valueMap = np.zeros((gridSize, gridSize))\n",
    "        self.states = [[i, j] for i in range(gridSize) for j in range(gridSize)]\n",
    "        self.size = gridSize\n",
    "        \n",
    "        # deterministic transition ?\n",
    "        self.transition_prob = 1 \n",
    "        \n",
    "        # initialize defender and invader states\n",
    "        self.new_state = [0, 0, 0, 0]\n",
    "        self.new_defender_state = [0, 0]\n",
    "        self.new_invader_state = [0, 0]\n",
    "        \n",
    "        # set territory state\n",
    "        self.territory_state = [4, 4]\n",
    "\n",
    "        # create a list of all possible states in the game\n",
    "        self.game_state_list = []\n",
    "        for defender_state in self.states:\n",
    "            for invader_state in self.states:\n",
    "                combined_states = tuple(defender_state + invader_state)\n",
    "                self.game_state_list.append(combined_states)\n",
    "        \n",
    "        # create 2 lists of states representing defender and invader victory\n",
    "        self.defender_won = []\n",
    "        self.invader_won = []\n",
    "        \n",
    "        # create states representing defender victory\n",
    "        for defender_state in self.states:\n",
    "            for invader_state in self.states:\n",
    "                distance = np.linalg.norm(np.array(defender_state) - np.array(invader_state))\n",
    "                # if the invader is not at territory and within the capture range of defender = defender won\n",
    "                if invader_state != self.territory_state and distance <= np.sqrt(2):\n",
    "                    combined_states = defender_state + invader_state\n",
    "                    self.defender_won.append(combined_states)\n",
    "           \n",
    "        # create states representing invader victory = anytime invader is at territory\n",
    "        for defender_state in self.states:               \n",
    "            combined_states = defender_state + self.territory_state\n",
    "            self.invader_won.append(combined_states)\n",
    "    \n",
    "    def possible_states(self):\n",
    "        \"\"\"\n",
    "        A function that returns a list of all possible states in the game\n",
    "        \"\"\"\n",
    "        return self.game_state_list\n",
    "    \n",
    "    def terminal_check(self, state):\n",
    "        \"\"\"\n",
    "        A function that checks whether the game is at a terminal state.\n",
    "        Terminal state happens when either the invader or defender has won.\n",
    "        \"\"\"\n",
    "        if state in self.defender_won:\n",
    "            status = \"Defender Won\"\n",
    "            terminal_check = True\n",
    "        elif state in self.invader_won:\n",
    "            status = \"Invader Won\"\n",
    "            terminal_check = True\n",
    "        else:\n",
    "            terminal_check = False\n",
    "            status = \"Game in Progress\"\n",
    "\n",
    "        return terminal_check, status\n",
    "    \n",
    "#     def transition_probability(self, transition):\n",
    "#         \"\"\"\n",
    "#         A function that returns the transition probability...?\n",
    "#         \"\"\"\n",
    "#         return self.transition_prob, reward\n",
    "\n",
    "    def next_state(self, current_state, defender_action, invader_action):\n",
    "        \"\"\"\n",
    "        A function that returns the next state\n",
    "        Input: current state [0,0] , defender_action [0, 1], invader_action [0,-1]\n",
    "        Output: next state array([x1,y1,x2,y2]) and reward (int)\n",
    "            - If the action takes the agent off grid, the agent remains in original state\n",
    "            - If defender won, reward is calculated based on manhattan distance between invader captured state\n",
    "            and territory\n",
    "            - If defender loss, reward is -100\n",
    "        \"\"\"\n",
    "        defender_state = []\n",
    "        invader_state = []\n",
    "        \n",
    "        # deconstruct current state [0,0,1,1] in to defender [0,0] and invader [1,1] state\n",
    "        for i in range(4):\n",
    "            if i < 2:\n",
    "                defender_state.append(current_state[i])\n",
    "            else:\n",
    "                invader_state.append(current_state[i])\n",
    "                \n",
    "        # get next state: state: [0, 0], action: [0, 1], new_state = [0, 1]\n",
    "        self.new_defender_state = list(np.array(defender_state) + np.array(defender_action))\n",
    "        self.new_invader_state = list(np.array(invader_state) + np.array(invader_action))\n",
    "\n",
    "        # if new defender states results in off the grid, return to original state\n",
    "        if -1 in self.new_defender_state or self.size in self.new_defender_state:\n",
    "            self.new_defender_state = defender_state\n",
    "        \n",
    "        # if new invader states results in off the grid, return to original state\n",
    "        if -1 in self.new_invader_state or self.size in self.new_invader_state:\n",
    "            self.new_invader_state = invader_state\n",
    "       \n",
    "        # combine the defender and invader state\n",
    "        self.new_state = self.new_defender_state\n",
    "        self.new_state.extend(self.new_invader_state)\n",
    "        \n",
    "#         # original rewards\n",
    "#         terminal, status = self.terminal_check(self.new_state)\n",
    "#         if terminal == True:\n",
    "#             if status == \"Defender Won\":\n",
    "#                 # defender reward if defender won (manhattan distance between invader captured state and territory)\n",
    "#                 distance_to_territory = sum(abs(np.array(self.new_invader_state) - np.array(self.territory_state)))\n",
    "#                 self.reward = distance_to_territory\n",
    "#             else:\n",
    "#                 # defender reward if invader won\n",
    "#                 self.reward = -100\n",
    "#         else:\n",
    "#             self.reward = 0\n",
    "            \n",
    "        # new rewards: penalizing defender for every step that invader takes closer to territory\n",
    "        terminal, status = self.terminal_check(self.new_state)\n",
    "        if terminal == True:\n",
    "            if status == \"Defender Won\":\n",
    "                # defender reward if defender won (manhattan distance between invader captured state and territory)\n",
    "                distance_to_territory = sum(abs(np.array(self.new_invader_state) - np.array(self.territory_state)))\n",
    "                self.reward = distance_to_territory\n",
    "            else:\n",
    "                # defender reward if invader won\n",
    "                self.reward = -100\n",
    "        else:\n",
    "            # penalize defender for every step that invader takes closer to territory\n",
    "            distance_to_territory = sum(abs(np.array(self.new_invader_state) - np.array(self.territory_state)))\n",
    "            self.reward = -(8 - distance_to_territory)\n",
    "            \n",
    "        return self.new_state, self.reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "invader_defender = Invader_Defender(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, reward = invader_defender.next_state([2,1,0,0], [-1, 0], [-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'Invader Won')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invader_defender.terminal_check([3, 5, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invader_defender.game_state_list[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
